#!/usr/bin/python

from pathlib import Path
import re
import os
from tqdm import tqdm
import argparse
from glob import escape
import requests
import hashlib
from enum import Enum

def sanitize(string) -> str:
    string = str(string)
    for char in ['"', "*", "/", ":", "<", "?", "\\", "|"]:
        string = string.replace(char, "_")
    for symbol in ["-\\>", "->", "\\>", ">"]:
        string = string.replace(symbol, "â”")
    return string


class File:
    def __init__(self, url, metadata):
        self.url = url
        self.ia_base_name = url[url.rindex("/"):]
        self.ext = self.ia_base_name[self.ia_base_name.rindex(".") + 1:]
        self.md5 = metadata.get("md5")
        self.title = metadata.get("title")
        self.track_num = metadata.get("track")

    def __str__(self):
        return f"{self.url}: {self.get_file_name()}"

    def get_track_num(self):
        return str(self.track_num).zfill(2) if self.track_num and str(self.track_num).isdigit() and int(
            self.track_num) < 10 else sanitize(self.track_num)

    def get_title(self):
        return sanitize(self.title) if self.title else f"Track {self.get_track_num()}"

    def get_file_name(self):
        return f"{self.get_track_num()} - {self.get_title()}.{self.ext}"


class SupportedFormats(Enum):
    FLAC = "flac"
    MP3 = "mp3"

    @classmethod
    def values(cls):
        return list(map(lambda f: f.value, cls))


def throw_error(message: str):
    print(message)
    exit(1)


def throw_with_cleanup(message: str, dir_to_remove):
    print(message)
    if os.path.exists(dir_to_remove) and not os.listdir(dir_to_remove):
        os.rmdir(dir_to_remove)
    exit(1)


def combine_list(items: list) -> str:
    return ", ".join(items) if hasattr(items, '__iter__') else items


def download_file(file: File, output: str) -> bool:
    print(f"Downloading {file.ia_base_name} as {file.get_file_name()}")
    max_attempts = 3

    attempts = 0
    while attempts < max_attempts:
        with requests.get(f"{file.url}", stream=True) as dl:
            if dl.status_code == 200:
                total_size = int(dl.headers.get("content-length"))
                with open(output, "wb") as out_file:
                    with tqdm(total=total_size, unit="B", unit_scale=True, initial=0, ascii=True) as progress:
                        for chunk in dl.iter_content(chunk_size=1024):
                            if chunk:
                                out_file.write(chunk)
                                progress.update(len(chunk))
                downloaded_md5 = hashlib.md5(open(output, "rb").read()).hexdigest()
                if file.md5 != downloaded_md5:
                    os.remove(output)
                    throw_with_cleanup(f"Failed to download {file.get_file_name()}, skipping show", Path(output).parent)
                else:
                    return True
            else:
                print(f"Failed to download {file.ia_base_name} as {file.get_file_name()}"
                      f"{', retrying...' if attempts < max_attempts else ''}")
                attempts += 1
    print(f"Failed to download {file.ia_base_name} as {file.get_file_name()}")
    return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument("url", help="enter a URL to retrieve")
    parser.add_argument("-o", "--output", help="directory to download files to (default: current directory)")
    parser.add_argument("-f", "--format", help="format to save files as (default: flac)")

    args = parser.parse_args()
    url = args.url
    target_dir = escape(Path(args.output)) if args.output else escape(Path(os.getcwd()))
    format = SupportedFormats.MP3

    if args.format in SupportedFormats.values():
        format = SupportedFormats(args.format)
    elif args.format is not None:
        throw_error("Invalid format specified")

    if not re.search("https?://archive.org/.*", url):
        throw_error("Invalid archive.org URL")

    if not os.path.exists(target_dir):
        throw_error("Output directory does not exist")

    page = requests.get(f"{url}?output=json").json()

    base_url = "https://" + page.get("server") + page.get("dir")

    metadata = page.get("metadata")

    artist = combine_list(metadata.get("creator"))
    location = combine_list(metadata.get("coverage"))
    venue = combine_list(metadata.get("venue"))
    date = combine_list(metadata.get("date"))

    output_dir = Path(f"{target_dir}/{date} - {artist} - {venue}, {location}")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"Saving to {output_dir}")
    print(f"Base URL: {base_url}")

    all_files = page.get("files")
    
    files = []
    for file in all_files:
        if "." in file and file[file.rindex(".") + 1:] == format.value:
            files.append(File(base_url + file, all_files[file]))

    for file in files:
        if not file.track_num:
            file.track_num = files.index(file) + 1

    if files:
        for file in files:
            if not download_file(file, f"{output_dir}/{file.get_file_name()}"):
                throw_with_cleanup(f"Failed to download {file.ia_base_name} as {file.get_file_name()}", output_dir)
    else:
        throw_with_cleanup(f"No files in {format} format found!", output_dir)

    if os.path.exists(output_dir) and not os.listdir(output_dir):
        if files:
            throw_with_cleanup("Failed to download all files!", output_dir)
        os.rmdir(output_dir)
